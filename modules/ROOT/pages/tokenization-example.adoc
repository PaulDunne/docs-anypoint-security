= Configure and Use Tokenization

== Set up Tokenization with API Gateway

To configure the tokenization service, you need the following:

* A Runtime Fabric with an ingress configured. See xref:1.0@runtime-fabric::index.adoc[the Runtime Fabric documentation].
* A Secrets group to store the tokenization table encryption keys. The tokenization service will create and store its own keys. See xref:asm-secret-group-concept.adoc[Secrets Manager documentation].
* A tokenization format: This describes the format of the data to be tokenized and how the data will be tokenized. See xref:tokenization-formats.adoc[Tokenization Formats].
* A tokenization service: This handles the actual tokenization requests and tokenizes and detokenizes the data. For security purposes, an API Gateway must protect this service.
* Api Gateway: This proxies requests to the tokenization service, provides authorization and authentication, and provides JSON protection for the tokenization service.

The reference model for this example tokenization service setup can be seen in the below diagram. In this diagram, a “Sensitive Data - Compliance Zone” is used to segregate the tokenization service from the general Runtime Fabric. This segregation occurs based on security needs.

The steps in this document walk you through the setup of data in the "Sensitive Data - Compliance Zone." If sensitive data is produced from a Mule Application serving external traffic (Client -> Edge -> Mule Application), this application might be included in the sensitive data zone.

image:tokenization-setup-example-diagram.png[]

== Prerequisites

=== Runtime Fabric with Ingress

This example shows a Runtime Fabric named "rtf231", which has an ingress that is using a certificate and private key in the secret group “alphatoken”. If you already have a Runtime Fabric and Secret Group configured, use those names in places of the ones in the example.

For more information, see xref:1.0@runtime-fabric::enable-inbound-traffic.adoc[Runtime Fabric ingress configuration].

The image below shows an example.

image:tokenization-example-rtf-ingress-config.png[]

=== Secret Group

Use Secrets Manager in the Anypoint platform Management Center to create and manage secret groups. For each tokenization service you create, you should also create a corresponding secret group in Secrets Manager to be used for that tokenization service only. No other tokenization service should use that secret group and no other secrets should be stored in that secret group.

When you delete a tokenization service, you can delete the corresponding secret group.

This is the recommended approach for several reasons:

. Since this secret group should explicitly be used for tokenization service, it will avoid other secrets from being deleted accidentally on delete of secret group. 
. You can create as many formats as you want and the secret group will never be exhausted. You can change the set of formats assigned to that tokenization service as often as you want and it will not exhaust the secret group.
. This unique association between the tokenization service and its secret group will prevent running out of the secrets of type VDP Context in a secret group. In the worst case, there will be 10 secrets created of type VDP Context, one for each VDP domain.

Normally, you can view, edit, or create secrets in Secrets Manager. However, the tokenization table keys are a non-editable part of the secret group. You can see the tokenization secrets under shared secret, but you are not allowed to modify them. Actions such as edit, cancel edit, and finish do not apply.

image:tokenization-example-shared-secret.png[]

Click *View* to see the name, type, and expiration of the secret group.

For more information about secret groups, see xref:asm-secret-group-concept.adoc[Secrets Manager documentation].

== Create the Tokenization Format

The tokenization format defines the way incoming data is converted. In this example, the domain type used is social security number (SSN). For more information about the supported tokenization formats see xref:tokenization-formats.adoc[Tokenization Formats].

To create the tokenization format:

. Sign into Anypoint Platform with the Organization Administrators role.
. Under *Management Center*, click *Anypoint Security*.
. In the menu on the left, click *Tokenization Format*.
. Click *Create Format*. +
The example below shows a social security data domain format named "sssnonly" with the options checkboxes unchecked.

image:tokenization-example-format.png[]

== Create the Tokenization Service

*[NOTE]*
 *You will need to download the automatically generated API Gateway Mule App. You must add TLS manually to the API Gateway Mule application connectors before you can make this service work. Tokenization involves sensitive data, and therefore, it works only with TLS.*

. Go to the *Runtime Manager­>Tokenization Service* page to create the service.
. Click *Create Tokenization Service*. The “Mule Cloud” means “Runtime Fabric Target”. The prerequisites you completed provide the information you need to fill out the form. This example shows the form filled in with the following values: +
* The Runtime Fabric named `rtf231` is in the *Mule Cloud* drop-down.
* The tokenization format `sssnonly` you created appears in the *Format* drop-down. You can assign more than one, or all, formats to one tokenization service.
* The Secret Group `alphatoken` appears in the *Secrets Group* drop-down.
* Select the number of tokenization service replicas to run. The tokenization service will run on worker nodes in Runtime Fabric.
* Optionally, you can adjust the logging level for the tokenization service.
. Click *Deploy* to create the tokenization table. +
A mapping table, which contains a large table of randomizations that are used at the core of tokenizing and detokenizing will pre-build. This is not a one-to-one table of mappings--it is used during internal steps to swap in and swap out randomizations in place of the actual data. The actual algorithm consists of these three steps:
** First stage transformation: Perform AES­FFX[radix] specific domain encryption using first stage symmetric key and tweak. This will redistribute the information contained within the data to be tokenized across all characters of the extracted data.
** Second stage transformation: Look­up and replace chunks of the clear­text data with the appropriate precomputed randomization in the mapping table.
** Third stage transformation: Perform AES­FFX[radix] specific domain encryption using third stage symmetric key and tweak. This will redistribute the information mapped by the multiple table look­ups of the preceding step across all of the extracted.

The tokenization mapping table build is a one-time action and can take as little as two minutes to build for an SSN only table (< 200 mb in size) and can take up to twenty minutes to build for larger formats such as “lax alphanumeric”. If many or all of the formats are selected, it can take a very long time to build the table for the service (~70 minutes). A table with all formats is roughly 2 GB in size.

image:tokenization-example-create-tokenization-service.png[]

Once you create the tokenization service, you need to create an API Gateway to route requests to the tokenization service.

== Creating an API Gateway for the Tokenization Service

Go to the Tokenization Service page in Runtime Manager to get the information you need for the implementation URL.

. In Runtime Manager, click *Tokenization Service* in the menu on the left.
. Click *Edit* for the tokenization service for which to create the API Gateway. +
image:tokenization-example-edit-token-service.png[]
. Confirm the Runtime Fabric assignment. +
The tokenization service name is “mytoken1” and the implementation URL will be: “https://mytoken1­tokenizer:3443”.

The service is available via HTTPS only. The tokenization service is hardcoded to listen on port 3443. The hostname portion is formed by taking the “Service Name” + “tokenizer” to arrive at the Kubernetes service name. The service name in this example is “mytoken1”.

image:tokenization-example-create-tokenization-service.png[]

== Create an API from the Tokenization RAML

Once you have the information you need to set up a routable tokenization service using an Api Gateway, create an API from the tokenization RAML.


. In Anypoint Platform, go to Exchange, and search for "Tokenization Service API."
. Download the `AMC Tokenizer` zip file.
. Go to *Design Center* and select *Create > API Specification*. For this example, the API specification is named "AMC Tokenizer". If you choose a different name, use that one in the below steps. +
image:tokenization-example-create-api-spec.png[]
. Next to *File*, select *Import* and upload the `AMC Tokenizer.zip` file you downloaded from Exchange in Step 1. +
image:tokenization-example-upload-amc-tokenizer.png[]
. Publish the asset to Anypoint Exchange.
. Navigate to *API Manager* from the top level Anypoint Platform menu.
. Select *Manage API > Manage API from Exchange*. +
image:tokenization-example-manage-api-from-exchange.png[]
. Enter the API configuration information, and click *Save*. The following image shows example values. +
image:tokenization-example-api-configuration.png[] +
*[NOTE]*
*HTTPS in Advanced options is not supported on Runtime Fabric.*
. Go to the Deployment Configuration, select your Runtime Fabric and Mule version, then enter a name for the API Gateway. The following example shows information for an API Gateway named "token2mule". +
image:tokenization-example-deploy-config.png[]
. Click *Deploy*. The button changes to *Redeploy* after the first deployment finishes. This deploys the API Gateway application.
. Download the API Gateway application to configure SSL within it:
.. In API Manager, go to the *Settings* page for your API.
.. Select *Actions > Download Proxy*. +
image:tokenization-example-download-proxy.png[]+
[NOTE]
This last step is necessary to configure TLS.

== Configure TLS

. Go to Anypoint Studio, and import the API Gateway. +
image:tokenization-example-import-api-gateway-studio.png[]
. Go to `src/main/resources` and add the keystore. In this example the keystore is named “tester.jks”. +
image:tokenization-example-keystore.png[]
. Add TLS to the listener side so you can later enable the `Last Mile Security` flag. To do this, first set the HTTPS flag. +
image:tokenization-example-set-https-flag.png[]
. Set the keystore information. In this example the trust store side is set to *insecure* and the keystore, alias, and password information has been added. +
image:tokenization-example-set-keystore-info.png[]
. Now set the HTTPS on the server tab, then configure your keystore on the TLS side to configure the client side. +
image:tokenization-example-configure-TLS.png[]
. Save the application and export it. Remember where it is saved so you can upload it in the next step.

== Add the TLS Enabled API Gateway

. In Anypoint Platform, go to the Runtime Manager page and click on the name of the API Gateway application `token2mule`.
. In the Settings page select *Choose File ­> Upload File* to upload the API Gateway application you modified in Anypoint Studio.
. Select the *Enable Last­Mile Security* option. Your settings should look similar to the below image. +
image:tokenization-example-add-tls-enabled-gateway.png[]
. Click *Deploy*. Once the application has a status of "Running" you are ready to test.

== Test the Tokenization Traffic

Once the application is running, you are ready to send traffic. It is a good idea to try the service first before you complete the additional steps to fully secure it. You can use POSTMAN or curl to test the service.

An example curl command is provided below. Replace the IP address with your own IP address. If you have used different names in the example for format, tokenization service, or API name, you will need to modify the example curl command.

To try a tokenization, send the following curl command:

curl ­-k ­­--resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/tokenization -­X POST -­H "Content­type: application/json" ­­--data '[{"data": "683­31­8102", "format": "ssndemo"}]'

HTTP/1.1 200 OK [{"data":"597­74­8102","status":"success"}]``

== Add Authorization and JSON Threat Protection

The Tokenization Service has no authentication or authorization. The only way to protect it is to only allow access through an Api Gateway with some type of Auth Policy enabled.

This example shows you how to add a basic auth policy to provide a very simple authentication.

. Go to the API Manager page where you created the API Gateway.
. In the menu on the left, click *Policies*.
. Create a “Simple Security manager” and add a simple username and password. +
image:tokenization-example-apply-simple-security.png[]
. Click *Apply New Policy* and add the “HTTP Basic Authorization” policy.
. Add the JSON threat protection policy. +
[NOTE]
A maximum of 200 tokenization or detokenization items can be included in each tokenization or detokenization request.

The below image shows an example. +
image:tokenization-example-json-threat-protection.png[] +
The Policies page should look similar to the below example. +
image:tokenization-example-policies-page.png[]

== Test Runtime Traffic with Basic Authorization

Run the following curl command to send traffic with the ``--user` flag for basic authorization.

`curl ­-k --­­resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/tokenization -­X POST ­-H "Content­type: application/json" ­­data '[{"data": "683­31­8102", "format": "ssndemo"}]' ­-k ­­--user test:test

HTTP/1.1 200 OK [{"data":"597­74­8102","status":"success"}]``

You can take the tokenized SSN from above and send it back into the service. You will receive the original SSN returned. Remember that the token returned is always format preserving.

`curl ­-k ­­--resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/detokenization ­-X POST ­-H "Content­type: application/json" ­­data '[{"data": "597­74­8102", "format": "ssndemo"}]' ­-k ­­--user test:test

HTTP/1.1 200 OK [{"data":"683­31­8102","status":"success"}][root@openstackvm32 pentest­ca]``

The following is an example of bad tokenization:

`curl ­v ­-k ­­--resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/tokenization -­X POST ­-H "Content­type: application/json" ­­data '[{"data": "597­74­8102­­­­­­­­sdsdsdsdsdsdsdsds", "format": "ssndemo"}]' ­-k ­­--user test:test

HTTP/1.1 422 Unprocessable Entity
[{"data":"","status":"failure","errorcode":1384,"error":"The social security number is invalid. It contains [26] characters. A social security number must have the format [###-##-####] where [\"#\"] represents a decimal digit."}]``

The following is an example of bad detokenization:

`curl ­v ­-k ­­--resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/detokenization ­-X POST ­-H "Content­type: application/json" ­­data '[{"data": "597­74­8102­­­­­­­­sdsdsdsdsdsdsdsds", "format": "ssndemo"}]' ­-k ­­--user test:test

HTTP/1.1 422 Unprocessable Entity
[{"data":"","status":"failure","errorcode":1380,"error":"The social security number is invalid. It contains [26] characters. A social security number must have the format [###-##-####] where [\"#\"] represents a decimal digit."}]``

The following is an example of bad tokenization JSON data stopped by Api Gateway protection:

`curl ­v ­-k ­­--resolve token2mule.ic.intel.com:443:10.230.36.230 \https://token2mule.ic.intel.com/tb/v1/detokenization ­-X POST -­H "Content­type: application/json" ­­data '[{{{}{{{}]]"data": "597­74­8102­­­­­­­­sdsdsdsdsdsdsdsds", "format": "ssndemo"}]' ­-k ­­--user test:test

HTTP/1.1 400 Bad Request
{ "errorcode": 1140, "message": "Error while parsing json [line 1 char 3, byte-offset 2]: Expected member name"}``

== Logs

You can use the tokenization summary message that is returned in the logs to determine traffic counts. To retrieve the logs, follow the instructions in the xref:1.0@runtime-fabric::configure-log-forwarding.adoc[Runtime Fabric documentation] for configuring log forwarding.

The log tag entry is `rtfTokenizationStatistics`, stats are a JSON string and rendered every 5 minutes at forced log entry of RTC `INFO` level (not subject to log level settings).

The following is an example of the tokenization summary message:

`<logEntry>
<header>
<time>2018-11-12T14:55:00.009667</time>
<node>icvlab11401</node>
<logType>RTC_BASE_MGMT</logType>
<logLevel>INFO</logLevel>
<process>WorkflowTest</process>
<pid>16766</pid>
<tid>16775</tid>
<file>cbrsrc/cbrcore/src/rtc/embedded/wfp/WfpTokenizationStatistics.cpp</file>
<line>98</line>
</header>
<body><rtfTokenizationStatistics>{"tokenizationStatistics":{"node":"icvlab11401","timestamp":"2018-11-12T20:55:00.009Z","tokenizeSuccess":2,"deTokenizeSuccess":6,"tokenizedBytes":6,"deTokenizedBytes":32,"tokenizeFailure":2,"deTokenizeFailure":2,"tokenizeFailedBytes":5,"deTokenizeFailedBytes":0}}</rtfTokenizationStatistics></body>+
</logEntry>`

[source,json,linenums]
{
 "tokenizationStatistics":{
   "node":"icvlab11401",
   "timestamp":"2018-11-12T20:55:00.009Z",
   "tokenizeSuccess":2,
   "deTokenizeSuccess":6,
   "tokenizedBytes":6,
   "deTokenizedBytes":32,
   "tokenizeFailure":2,
   "deTokenizeFailure":2,
   "tokenizeFailedBytes":5,
   "deTokenizeFailedBytes":0
 }
}

Failures are only incremented for actual tokenization and detokenization failures. Other failures, such as protocol errors in the requests, do not count towards the failure statistics. An example of a failure is an unknown token string that can't be detokenized.

Counts are cumulative from the start of each individual pod (replica) until its death.
